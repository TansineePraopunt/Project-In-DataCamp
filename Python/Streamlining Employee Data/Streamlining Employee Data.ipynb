{"cells":[{"metadata":{"dc":{"key":"4"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 1. Loading data from CSV and Excel files\n<p>You just got hired as the first and only data practitioner at a small business experiencing exponential growth. The company needs more structured processes, guidelines, and standards. Your first mission is to structure the human resources data. The data is currently scattered across teams and files and comes in various formats: Excel files, CSVs, JSON files, SQL databasesâ€¦</p>\n<p>The Head of People Operations wants to have a general view gathering all available information about a specific employee. Your job is to gather it all in a file that will serve as the reference moving forward. You will merge all of this data in a pandas DataFrame before exporting to CSV.</p>\n<p>Data management at your company is not the best, but you need to start somewhere. You decide to tackle the most straightforward tasks first, and to begin by loading the company office addresses. They are currently saved into a CSV file, <code>office_addresses.csv</code>, which the Office Manager sent over to you. Additionally, an HR manager you remember interviewing with gave you access to the Excel file, <code>employee_information.xlsx</code>, where the employee addresses are saved. You need to load these datasets in two separate DataFrames.</p>"},{"metadata":{"dc":{"key":"4"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Import the library you need\nimport pandas as pd\n\n# Load office_addresses.csv\ndf_office_addresses = pd.read_csv(\"../input/employee-data/office_addresses.csv\")\n\n# Load employee_information.xlsx\ndf_employee_addresses = pd.read_excel(\"../input/employee-data/employee_information.xlsx\")\n\n# Take a look at the first rows of the DataFrames\ndisplay(df_office_addresses)\ndisplay(df_employee_addresses)","execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/employee-data/office_addresses.csv'","traceback":["---------------------------------------------------------------------------","FileNotFoundError                         Traceback (most recent call last)","<ipython-input-2-65cb37fbef9d> in <module>\n      3 \n      4 # Load office_addresses.csv\n----> 5 df_office_addresses = pd.read_csv(\"../input/employee-data/office_addresses.csv\")\n      6 \n      7 # Load employee_information.xlsx\n","/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\n    686     )\n    687 \n--> 688     return _read(filepath_or_buffer, kwds)\n    689 \n    690 \n","/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py in _read(filepath_or_buffer, kwds)\n    452 \n    453     # Create the parser.\n--> 454     parser = TextFileReader(fp_or_buf, **kwds)\n    455 \n    456     if chunksize or iterator:\n","/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py in __init__(self, f, engine, **kwds)\n    946             self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n    947 \n--> 948         self._make_engine(self.engine)\n    949 \n    950     def close(self):\n","/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py in _make_engine(self, engine)\n   1178     def _make_engine(self, engine=\"c\"):\n   1179         if engine == \"c\":\n-> 1180             self._engine = CParserWrapper(self.f, **self.options)\n   1181         else:\n   1182             if engine == \"python\":\n","/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py in __init__(self, src, **kwds)\n   2008         kwds[\"usecols\"] = self.usecols\n   2009 \n-> 2010         self._reader = parsers.TextReader(src, **kwds)\n   2011         self.unnamed_cols = self._reader.unnamed_cols\n   2012 \n","pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.__cinit__()\n","pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._setup_parser_source()\n","FileNotFoundError: [Errno 2] No such file or directory: '../input/employee-data/office_addresses.csv'"]}]},{"metadata":{"dc":{"key":"12"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 2. Loading employee data from Excel sheets\n<p>It turns out the <code>employee_information.xlsx</code> file also holds information about emergency contacts for each employee in a second sheet titled <code>emergency_contacts</code>. However, this sheet was edited at some point, and the header was removed! Looking at the data, you were able to figure out what the header should be, and you confirmed that they were appropriate with the HR manager: <code>employee_id</code>, <code>last_name</code>, <code>first_name</code>, <code>emergency_contact</code>, <code>emergency_contact_number</code>, <code>relationship</code>.</p>"},{"metadata":{"dc":{"key":"12"},"tags":["sample_code"],"trusted":true,"collapsed":true},"cell_type":"code","source":"# Load data from the second sheet of employee_information.xlsx\ndf_emergency_contacts = pd.read_excel(\"../input/employee-data/employee_information.xlsx\", sheet_name=\"emergency_contacts\", header=None)\n\n# Declare a list of new column names\nemergency_contacts_header = [\"employee_id\", \"last_name\", \"first_name\", \"emergency_contact\", \"emergency_contact_number\", \"relationship\"]\n\n# Rename the columns\ndf_emergency_contacts.columns = emergency_contacts_header\n\ndf_emergency_contacts.head()","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"19"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 3. Loading role data from JSON files\n<p>All right, you're making good progress! Now the next step is to gather information about employee roles, teams, and salaries. This information usually lives in a human resources management system, but the Head of People Operations exported the data for you into a JSON file titled <code>employee_roles.json</code>.</p>\n<p>Looking at the JSON file, you see entries are structured in a specific way. It is built as a Python dictionary: the keys are employee IDs, and each employee ID has a corresponding dictionary value holding role, salary, and team information. Here are the first few lines of the file:</p>\n<pre><code>{\"A2R5H9\":\n  {\n    \"title\": \"CEO\",\n    \"monthly_salary\": \"$4500\",\n    \"team\": \"Leadership\"\n  },\n ...\n}\n</code></pre>\n<p>Load the JSON file to a variable <code>df_employee_roles</code>, choosing the appropriate orientation.</p>"},{"metadata":{"dc":{"key":"19"},"tags":["sample_code"],"trusted":true,"collapsed":true},"cell_type":"code","source":"# Load employee_roles.json\ndf_employee_roles = pd.read_json(\"../input/employee-data/employee_roles.json\", orient='index')\ndf_employee_roles = df_employee_roles.reindex(sorted(df_employee_roles.columns), axis=1)\n\n# Take a look at the first rows of the DataFrame\ndf_employee_roles.head()","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"26"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 4. Merging several DataFrames into one\n<p>You now have all the data required! All that's left is bringing it all in a unique DataFrame. This unique DataFrame will enable the Head of People Operations to access all employee data at once.</p>\n<p>In this step, you will merge all DataFrames. In the next step, you will remove duplicates and reorganize the columns - don't worry about this for now.</p>"},{"metadata":{"dc":{"key":"26"},"tags":["sample_code"],"trusted":true,"collapsed":true},"cell_type":"code","source":"# Merge df_employee_addresses with df_emergency_contacts\ndf_employees = df_employee_addresses.merge(df_emergency_contacts, how=\"left\", on=\"employee_id\", copy=False)\n\n# Merge df_employees with df_employee_roles\ndf_employees = df_employees.merge(df_employee_roles, how=\"left\", left_on=\"employee_id\", right_on=df_employee_roles.index, copy=False)\n\n# Merge df_employees with df_office_addresses\ndf_employees = df_employees.merge(df_office_addresses, how=\"left\", left_on=\"employee_country\", right_on=\"office_country\", copy=False)\n\n# Take a look at the first rows of the DataFrame and its columns\ndisplay(df_employees.head())\ndisplay(df_employees.columns)","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"33"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 5. Editing column names\n<p>Now that you merged all of your DataFrames into one let's make sure you have the information required by People Ops.</p>\n<p>Currently, your <code>df_employees</code> DataFrame has the following column titles:\n<code>employee_id</code>, <code>employee_last_name</code>, <code>employee_first_name</code>, <code>employee_country</code>, <code>employee_city</code>, <code>employee_street</code>, <code>employee_street_number</code>, <code>last_name</code>, <code>first_name</code>, <code>emergency_contact</code>, <code>emergency_contact_number</code>, <code>relationship</code>, <code>monthly_salary</code>, <code>team</code>, <code>title</code>,  <code>office</code>, <code>office_country</code>, <code>office_city</code>, <code>office_street</code>, <code>office_street_number</code>.</p>\n<p>The columns <code>employee_last_name</code> and <code>last_name</code> are duplicates. The columns <code>employee_first_name</code> and <code>first_name</code> are duplicates as well. On top of this, People Ops wants to rename some of the columns:</p>\n<ul>\n<li><code>employee_id</code> should be <code>id</code></li>\n<li><code>employee_country</code> should be <code>country</code></li>\n<li><code>employee_city</code> should be <code>city</code></li>\n<li><code>employee_street</code> should be <code>street</code></li>\n<li><code>employee_street_number</code> should be <code>street_number</code></li>\n<li><code>emergency_contact_number</code> should be <code>emergency_number</code></li>\n<li><code>relationship</code> should be <code>emergency_relationship</code></li>\n</ul>\n<p><strong>So your header should look like this in the end:</strong>\n<code>id</code>, <code>country</code>, <code>city</code>, <code>street</code>, <code>street_number</code>, <code>last_name</code>, <code>first_name</code>, <code>emergency_contact</code>, <code>emergency_number</code>, <code>emergency_relationship</code>, <code>monthly_salary</code>, <code>team</code>, <code>title</code>, <code>office</code>, <code>office_country</code>, <code>office_city</code>, <code>office_street</code>, <code>office_street_number</code>.</p>"},{"metadata":{"dc":{"key":"33"},"tags":["sample_code"],"trusted":true,"collapsed":true},"cell_type":"code","source":"# Drop the columns\ndf_employees_renamed = df_employees.drop([\"employee_first_name\", \"employee_last_name\"], axis=1)\n\n# New columns names\nnew_column_names = {\"employee_id\": \"id\",\n                    \"employee_country\": \"country\",\n                    \"employee_city\": \"city\",\n                    \"employee_street\": \"street\",\n                    \"employee_street_number\": \"street_number\",\n                    \"relationship\": \"emergency_relationship\",\n                    \"emergency_contact_number\": \"emergency_number\"}\n\n# Rename the columns\ndf_employees_renamed = df_employees_renamed.rename(columns=new_column_names)\n\n# Take a look at the first rows of the DataFrame\ndf_employees_renamed.head()","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"40"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 6. Changing column order\n<p>Now that you have the appropriate column names, you can reorder the columns.</p>"},{"metadata":{"dc":{"key":"40"},"tags":["sample_code"],"trusted":true,"collapsed":true},"cell_type":"code","source":"# Declare a list for the new column's order and reorder columns\nnew_column_order = [\"id\", \"last_name\", \"first_name\", \"title\", \"team\", \"monthly_salary\", \n                    \"country\", \"city\", \"street\", \"street_number\",\n                    \"emergency_contact\", \"emergency_number\", \"emergency_relationship\",\n                    \"office\", \"office_country\", \"office_city\", \"office_street\", \"office_street_number\"]\n\n# Reorder the columns\ndf_employees_ordered = df_employees_renamed.reindex(new_column_order, axis=1)\n\n# Take a look at the result\ndf_employees_ordered.head()","execution_count":null,"outputs":[]},{"metadata":{"dc":{"key":"47"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 7. The last minute request\n<p>Last touches! You were ready to let People Ops know that the DataFrame was ready, but the department head just went over to your desk after lunch, asking about some last-minute requirements.</p>\n<p>Let's polish the DataFrame before exporting the data, sending it over to People Ops, and deploying the pipeline:</p>\n<ul>\n<li>All street numbers should be integers</li>\n<li>The index should be the actual employee ID rather than the row number</li>\n<li>If the value for office is <code>NaN</code> then the employee is remote: add a column named \"status\", right after <code>monthly_salary</code> indicating whether the employee is \"On-site\" or \"Remote.\"</li>\n</ul>"},{"metadata":{"dc":{"key":"47"},"tags":["sample_code"],"trusted":true},"cell_type":"code","source":"# Reset the index and drop the column\ndf_employees_final = df_employees_ordered.set_index(\"id\", drop=True)\n\nstatus_list = []\n\n# Loop through the row values and append to status_list accordingly\nfor i, row in df_employees_final.iterrows():\n    if pd.isnull(row[\"office\"]):\n        status_list.append(\"Remote\")\n    else:\n        status_list.append(\"On-site\")\n\n# Insert status_list as a new column\ndf_employees_final.insert(loc=5, column=\"status\", value=status_list)\n\n# Take a look at the first rows of the DataFrame\ndf_employees_final.head()","execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df_employees_ordered' is not defined","traceback":["---------------------------------------------------------------------------","NameError                                 Traceback (most recent call last)","<ipython-input-4-91cac7edc8f8> in <module>\n      1 # Reset the index and drop the column\n----> 2 df_employees_final = df_employees_ordered.set_index(\"id\", drop=True)\n      3 \n      4 status_list = []\n      5 \n","NameError: name 'df_employees_ordered' is not defined"]}]},{"metadata":{"dc":{"key":"54"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"cell_type":"markdown","source":"## 8. Saving your work\n<p>Good job! You now have everything People Ops requested. The different people responsible for these various files can currently keep working on these files if they want. As long as they save it in the <code>datasets</code> folder, People Ops will have to execute this unique script to obtain just one file from the ones scattered across different teams.</p>\n<p>You bumped into the Head of People Ops and shared a few caveats and areas of improvement. She booked a meeting with you so you can explain:</p>\n<ul>\n<li>How the current structure isn't robust to role changes: what if an existing employee takes on a new role?</li>\n<li>How the current structure doesn't fit best practices in terms of database schema:<ul>\n<li>having data all over the place like it's the case right now is a no-go</li>\n<li>but gathering everything in a single table is inefficient: you have to query all information even if all you want is a phone number</li>\n<li>there should be a single SQL database for employee data, with several tables that can be joined</li>\n<li>views can be built on top of the database to simplify non-data practitioners access.</li></ul></li>\n</ul>\n<p>In any case, you still need to show up with what was requested - so let's export your DataFrame to a CSV file.</p>"},{"metadata":{"dc":{"key":"54"},"tags":["sample_code"],"trusted":true,"collapsed":true},"cell_type":"code","source":"# Write to CSV\ndf_employees_final.to_csv(\"employee_data.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}